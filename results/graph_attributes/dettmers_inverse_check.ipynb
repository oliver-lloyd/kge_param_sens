{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('libkge': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e41f4a0484c58ef9a24f0282607fbe75b061b504ca892ae0b5a7a5592c3b9b8e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     job_id dataset               model  reciprocal     job  \\\n",
       "0  0846d846    umls            distmult           1  search   \n",
       "1  0def3a9b    umls  relational_tucker3           0  search   \n",
       "2  93f0291e    umls             complex           1  search   \n",
       "3  b5f61ac0    umls              transh           0  search   \n",
       "4  a89e6474  wn18rr              rescal           0  search   \n",
       "\n",
       "            job_type  split  epoch  avg_loss  avg_penalty  ...  \\\n",
       "0  negative_sampling  valid     30       NaN          NaN  ...   \n",
       "1  negative_sampling  valid     30       NaN          NaN  ...   \n",
       "2             KvsAll  valid    115       NaN          NaN  ...   \n",
       "3  negative_sampling  valid    150       NaN          NaN  ...   \n",
       "4  negative_sampling  valid    400       NaN          NaN  ...   \n",
       "\n",
       "   entity_embedder.regularize_weight relation_embedder.regularize_weight  \\\n",
       "0                               None                                None   \n",
       "1                               None                                None   \n",
       "2                               None                                None   \n",
       "3                               None                                None   \n",
       "4                               None                                None   \n",
       "\n",
       "   entity_embedder.dropout  relation_embedder.dropout l_norm  \\\n",
       "0                     None                       None   None   \n",
       "1                     None                       None   None   \n",
       "2                     None                       None   None   \n",
       "3                     None                       None   None   \n",
       "4                     None                       None   None   \n",
       "\n",
       "   feature_map_dropout projection_dropout  convolution_bias  \\\n",
       "0                 None               None              None   \n",
       "1                 None               None              None   \n",
       "2                 None               None              None   \n",
       "3                 None               None              None   \n",
       "4                 None               None              None   \n",
       "\n",
       "   entity_embedder.normalize.p  relation_embedder.normalize.p  \n",
       "0                         None                           None  \n",
       "1                         None                           None  \n",
       "2                         None                           None  \n",
       "3                         None                           None  \n",
       "4                         None                           None  \n",
       "\n",
       "[5 rows x 40 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>job_id</th>\n      <th>dataset</th>\n      <th>model</th>\n      <th>reciprocal</th>\n      <th>job</th>\n      <th>job_type</th>\n      <th>split</th>\n      <th>epoch</th>\n      <th>avg_loss</th>\n      <th>avg_penalty</th>\n      <th>...</th>\n      <th>entity_embedder.regularize_weight</th>\n      <th>relation_embedder.regularize_weight</th>\n      <th>entity_embedder.dropout</th>\n      <th>relation_embedder.dropout</th>\n      <th>l_norm</th>\n      <th>feature_map_dropout</th>\n      <th>projection_dropout</th>\n      <th>convolution_bias</th>\n      <th>entity_embedder.normalize.p</th>\n      <th>relation_embedder.normalize.p</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0846d846</td>\n      <td>umls</td>\n      <td>distmult</td>\n      <td>1</td>\n      <td>search</td>\n      <td>negative_sampling</td>\n      <td>valid</td>\n      <td>30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0def3a9b</td>\n      <td>umls</td>\n      <td>relational_tucker3</td>\n      <td>0</td>\n      <td>search</td>\n      <td>negative_sampling</td>\n      <td>valid</td>\n      <td>30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>93f0291e</td>\n      <td>umls</td>\n      <td>complex</td>\n      <td>1</td>\n      <td>search</td>\n      <td>KvsAll</td>\n      <td>valid</td>\n      <td>115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b5f61ac0</td>\n      <td>umls</td>\n      <td>transh</td>\n      <td>0</td>\n      <td>search</td>\n      <td>negative_sampling</td>\n      <td>valid</td>\n      <td>150</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a89e6474</td>\n      <td>wn18rr</td>\n      <td>rescal</td>\n      <td>0</td>\n      <td>search</td>\n      <td>negative_sampling</td>\n      <td>valid</td>\n      <td>400</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 40 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Load results\n",
    "results = pd.read_csv('../all_trials.csv')\n",
    "results.dataset.loc[results.dataset == 'wnrr'] = 'wn18rr'\n",
    "\n",
    "# Combine split columns\n",
    "model_names = list(results.model.unique())\n",
    "for column in results.columns:\n",
    "    if column.split('.')[0] in model_names:\n",
    "        actual_column = '.'.join(column.split('.')[1:])\n",
    "        results[actual_column] = None\n",
    "        for column2 in results.columns:\n",
    "            if actual_column in column2 and actual_column != column2:\n",
    "                for i, val in enumerate(results[column2]):\n",
    "                    if pd.notna(val):\n",
    "                        results[actual_column][i] = val\n",
    "                results.drop(columns=[column2], inplace=True)\n",
    "\n",
    "    \n",
    "results.head()"
   ]
  },
  {
   "source": [
    "Median performance on UMLS is substantially higher than for the other two datasets. Since FB15K-237 and WN18RR have been specifically constructed to avoid test leakage through inverse relations [(Detmers et al)](https://arxiv.org/pdf/1707.01476.pdf), it is worth investigating whether this phenomenon is inflating the performance on UMLS."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_relation_proportion(predicate1, predicate2, train_list):\n",
    "\n",
    "    pred1_list = train_list.loc[train_list.p == predicate1]\n",
    "    pred2_list = train_list.loc[train_list.p == predicate2]\n",
    "\n",
    "    inverse_count = len([i for i, triple in pred1_list.iterrows() if ((pred2_list['s'] == triple.o) & (pred2_list['o'] == triple.s)).any()])\n",
    "    inverse_proportion = inverse_count/len(pred1_list)\n",
    "\n",
    "    return [predicate1, predicate2, inverse_proportion]\n",
    "\n",
    "\n",
    "def parallel_inverse_check(train, valid, test):\n",
    "\n",
    "    # Calculate inverse relation threshold (using Detmers et al's definition)\n",
    "    total_edges = len(train) + len(test) + len(valid)\n",
    "    inverse_threshold = 0.99 - len(test)/total_edges - len(valid)/total_edges\n",
    "\n",
    "    # Calculate all inverse relation proportions\n",
    "    args = [[predicate1, predicate2, train] for predicate1 in train.p.unique() for predicate2 in train.p.unique() if predicate1 != predicate2]\n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        inverse_proportions = pool.starmap(inverse_relation_proportion, args)\n",
    "    inverse_check_df = pd.DataFrame(inverse_proportions)\n",
    "    inverse_check_df.columns = ['predicate', 'inverse', 'inverse_proportion']\n",
    "\n",
    "    # Return inverse relations with proportions over the threshold\n",
    "    leaking_rels = inverse_check_df.loc[inverse_check_df.inverse_proportion >= inverse_threshold]\n",
    "    return leaking_rels.sort_values('inverse_proportion', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           predicate  \\\n",
       "0                                      derivative_of   \n",
       "1                                      derivative_of   \n",
       "2                                           precedes   \n",
       "3                                          degree_of   \n",
       "4                                           precedes   \n",
       "5  /location/administrative_division/first_level_...   \n",
       "\n",
       "                       inverse  inverse_proportion    dataset  \n",
       "0                     contains            1.000000       umls  \n",
       "1                    surrounds            1.000000       umls  \n",
       "2                      affects            0.842105       umls  \n",
       "3                      affects            0.814815       umls  \n",
       "4                    result_of            0.789474       umls  \n",
       "5  /location/location/contains            0.879433  fb15k-237  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predicate</th>\n      <th>inverse</th>\n      <th>inverse_proportion</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>derivative_of</td>\n      <td>contains</td>\n      <td>1.000000</td>\n      <td>umls</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>derivative_of</td>\n      <td>surrounds</td>\n      <td>1.000000</td>\n      <td>umls</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>precedes</td>\n      <td>affects</td>\n      <td>0.842105</td>\n      <td>umls</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>degree_of</td>\n      <td>affects</td>\n      <td>0.814815</td>\n      <td>umls</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>precedes</td>\n      <td>result_of</td>\n      <td>0.789474</td>\n      <td>umls</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>/location/administrative_division/first_level_...</td>\n      <td>/location/location/contains</td>\n      <td>0.879433</td>\n      <td>fb15k-237</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Check for inverse relations in the datasets\n",
    "\n",
    "run = False  # This cell took approx 4 hours on 4 cores, dont run unless output file is lost\n",
    "if run:\n",
    "    detmers_check = pd.DataFrame()\n",
    "\n",
    "    for dataset in ['umls', 'wnrr', 'fb15k-237']:\n",
    "        print(f'Processing {dataset}')\n",
    "        # Read in edge splits\n",
    "        train_set = pd.read_csv(f'../../kge/data/{dataset}/train.txt', sep='\\t', header=None)\n",
    "        train_set.columns = ['s', 'p', 'o']\n",
    "        test_set = pd.read_csv(f'../../kge/data/{dataset}/test.txt', sep='\\t', header=None)\n",
    "        valid_set = pd.read_csv(f'../../kge/data/{dataset}/valid.txt', sep='\\t', header=None)\n",
    "\n",
    "        # Check for inverse relations\n",
    "        inverse_results = parallel_inverse_check(train_set, valid_set, test_set)\n",
    "        inverse_results['dataset'] = dataset\n",
    "\n",
    "        # Store\n",
    "        detmers_check = detmers_check.append(inverse_results)\n",
    "    \n",
    "\n",
    "else:\n",
    "    detmers_check = pd.read_csv('graph_attributes/detmers_inverse_check.csv')\n",
    "\n",
    "detmers_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "detmers_check.columns = ['predicate', 'inverse', 'inverse_proportion', 'dataset']\n",
    "detmers_check.to_csv('detmers_inverse_check_umls_fb15k_wnrr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Leaking relation \"degree_of\" composes 0.605% of the test set edges\nLeaking relation \"precedes\" composes 1.362% of the test set edges\nLeaking relation \"derivative_of\" composes 0.0% of the test set edges\n"
     ]
    }
   ],
   "source": [
    "# Check how frequent these relations are in the UMLS testing set\n",
    "umls_test = pd.read_csv(f'../../kge/data/umls/test.txt', sep='\\t', header=None)\n",
    "umls_inverse = detmers_check.loc[detmers_check.dataset == 'umls']\n",
    "for leak_rel in umls_inverse.predicate.unique():\n",
    "    test_proportion = len(umls_test.loc[umls_test[1] == leak_rel])/len(umls_test)\n",
    "    test_percentage = test_proportion * 100\n",
    "    print(f'Leaking relation \"{leak_rel}\" composes {round(test_percentage, 3)}% of the test set edges')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Leaking relation \"/location/administrative_division/first_level_division_of\" composes 0.0% of the test set edges\n"
     ]
    }
   ],
   "source": [
    "# Check how frequent these relations are in the FB15k-237 testing set\n",
    "fb_test = pd.read_csv(f'../../kge/data/fb15k-237/test.txt', sep='\\t', header=None)\n",
    "fb_inverse = detmers_check.loc[detmers_check.dataset == 'fb15k-237']\n",
    "for leak_rel in fb_inverse.predicate.unique():\n",
    "    test_proportion = len(fb_test.loc[fb_test[1] == leak_rel])/len(fb_test)\n",
    "    test_percentage = test_proportion * 100\n",
    "    print(f'Leaking relation \"{leak_rel}\" composes {round(test_percentage, 3)}% of the test set edges')"
   ]
  },
  {
   "source": [
    "The table above shows that test leakage is indeed occurring in the UMLS dataset. Three different relations - 'derivative_of'; 'precedes'; and 'degree_of' - can be predicted unreasonably well using nothing but the inverse of another relation. This is potentially problematic because a link predictor could forgo proper modeling of the graph, instead utilising this phenomenon to inflate its perceived performance. However, in this case, these leaking edges compose less than 2% of the testing dataset and therefore cannot be the sole reason for the models' improved MRR on UMLS."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}